### Lecture: 7. Recurrent Neural Networks II
#### Date: Apr 15
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1819/slides/?07
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1819/slides.pdf/npfl114-07.pdf,PDF Slides
#### Video: https://slideslive.com/38907189/deep-learning-lecture-8-recurrent-neural-networks-ii-word-embeddings, 2018 Video I
#### Video: https://slideslive.com/38907422/deep-learning-lecture-9-recurrent-neural-networks-iii-machine-translation, 2018 Video II
#### Video: https://slideslive.com/38907562/deep-learning-lecture-11-sequence-prediction-reinforcement-learning, 2018 Video III
#### Video: https://slideslive.com/38910718/deep-learning-lecture-12-sequence-prediction-ii-reinforcement-learning-ii, 2018 Video IV
#### Lecture assignment: tagger_we
#### Lecture assignment: tagger_cle_rnn
#### Lecture assignment: tagger_cle_cnn
#### Lecture assignment: speech_recognition

- Gated Recurrent Unit (GRU) [Section 10.10.2 of DLB, *[Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio: Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)*]
- Highway Networks [[Rupesh Kumar Srivastava, Klaus Greff, Jürgen Schmidhuber: **Training Very Deep Networks**](https://arxiv.org/abs/1507.06228)]
- RNN Regularization
  - Variational Dropout [[Yarin Gal, Zoubin Ghahramani: **A Theoretically Grounded Application of Dropout in Recurrent Neural Networks**](https://arxiv.org/abs/1512.05287)]
  - Layer Normalization [[Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton: **Layer Normalization**](https://arxiv.org/abs/1607.06450)]
- Word Embeddings [Section 14.2.4 of DLB]
- Bidirectional RNN [Section 10.3 of DLB]
- Character-level embeddings using Recurrent neural networks [C2W model from [Wang Ling, Tiago Luís, Luís Marujo, Ramón Fernandez Astudillo, Silvio Amir, Chris Dyer, Alan W. Black, Isabel Trancoso: Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](http://arxiv.org/abs/1508.02096)]
- Character-level embeddings using Convolutional neural networks [CharCNN from [Yoon Kim, Yacine Jernite, David Sontag, Alexander M. Rush: Character-Aware Neural Language Models](https://arxiv.org/abs/1508.06615)]
- Conditional Random Fields (CRF) loss [Sections 3.4.2 and A.7 of [R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, P. Kuksa: **Natural Language Processing (Almost) from Scratch**](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)]
